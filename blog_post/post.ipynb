{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8b281e10",
   "metadata": {},
   "source": [
    "Title: Data Enrichment for ML Model Deployments\n",
    "Date: 2022-05-01 07:00\n",
    "Category: Blog\n",
    "Slug: data-enrichment-for-ml-models\n",
    "Authors: Brian Schmidt\n",
    "Summary: Machine learning models need data to make predictions. When deploying a model to a production setting, this data is not necessarily available from the client system that is requesting the prediction. When this happens, some other source is needed for the data that is required by the model but not provided by the client system. The process of accessing the data and joining it to the client's prediction request is called data enrichment. In all cases, the model itself should not need to be modified in order to do data enrichment, the process should be transparent to the model. In this blog post, we'll show a method for doing data enrichment that does not require the model itself to be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38521c2f",
   "metadata": {},
   "source": [
    "# Data Enrichment for ML Model Deployments\n",
    "\n",
    "In the [previous blog post](https://www.tekhnoal.com/ml-model-decorators.html) we introduced the decorator pattern for ML model deployments and then showed how to use the pattern to build extensions for machine learning models. The extensions that we showed in the previous post were added without having to modify the machine learning model code at all, we were able to do it by creating a decorator class that wrapped the model. In this blog post we’ll use decorators to add data enrichment capabilities to an ML model.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Machine learning models need data to make predictions. When deploying a model to a production setting, this data is not necessarily available from the client system that is requesting the prediction. When this happens, some other source is needed for the data that is required by the model but not provided by the client system. The process of accessing the data and joining it to the client's prediction request is called data enrichment. In all cases, the model itself should not need to be modified in order to do data enrichment, the process should be transparent to the model. In this blog post, we'll show a method for doing data enrichment that does not require the model itself to be modified.\n",
    "\n",
    "Data enrichment is often done because the client system does not have access to the data that the model needs to make a prediction. In this case, the client must provide a field that the model can use to find the data that it needs to make a prediction, we'll call this the \"index field\". For example, in order to load customer details that need to be used to make a prediction, we need to get a customer id field that uniquely identifies the customer record.\n",
    "Once the data is loaded from a data source, the model can be called to make a prediction using the fields that it expects.\n",
    "\n",
    "Other times, the client system is simply not the right place to manage the data that the model needs for predictions because of it's complexity. In this case, we would like to prevent the client system from having to manage data that really does not fall within it's responsabilities. In order to allow the client system to use the model without having to manage the extra data, we can add data enrichment capabilities to the model deployment.\n",
    "\n",
    "Data enrichment simplifies the work of the client system because a client system can simply provide a way to find the correct data to the deployed ML model. The model deployment is then responsible for going and fetching the correct record, joining it to the data provided by the client system, and making a prediction. Data enrichment also prevents the client system from having to manage the data needed by the model, which keeps the two systems from becoming too coupled. \n",
    "\n",
    "One more benefit of doing data enrichment is that the model can evolve by using new fields for predictions without affecting the client system at all. By having the model access the data that it needs to make a prediction, the model can access new data and the client system is not responsible for providing or managing the new fields. This allows the deployed model to evolve more easily.\n",
    "\n",
    "In this blog post, we’ll show how to create a simple decorator that is able to access a database in order to do data enrichment for an ML model that is deployed to a production system. We'll also show how to deploy the decorator along with the model to a RESTful service, and how to create the necessary database to hold the data.\n",
    "\n",
    "All of the code is available in this [github repository](https://github.com/schmidtbri/data-enrichment-for-ml-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542c48c",
   "metadata": {},
   "source": [
    "## Software Architecture\n",
    "\n",
    "The decorator that we will be building requires an outside database in order to access data to do data enrichment. The software architecture will be a little more complicated because we’ll have to deploy a service for the model as well as a database for the data.\n",
    "\n",
    "![Software Architecture](software_architecture.png)\n",
    "![Software Architecture]({attach}software_architecture.png){ width=100% }\n",
    "\n",
    "The client system accesses the model by reaching out to the model service which hosts both the model and the decorator that we will be building in this blog post. The decorator is the software component that does the data enrichment needed by the model. The decorator reaches out to the database to access data needed by the model, provides the data to the model to make a prediction, and then returns the prediction to the client system. \n",
    "\n",
    "To store the data that we want to use for enrichment, we’ll use a PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefb4db",
   "metadata": {},
   "source": [
    "# Installing a Model\n",
    "\n",
    "To make this blog post a little shorter we won't train a completely new model. Instead we'll install a model that we've built in [a previous blog post](https://www.tekhnoal.com/regression-model.html). The code for the model is in [this github repository](https://github.com/schmidtbri/regression-model).\n",
    "\n",
    "To install the model, we can use the pip command and point it at the github repo of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df232bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install -e git+https://github.com/schmidtbri/regression-model#egg=insurance_charges_model\n",
    "  \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2754c",
   "metadata": {},
   "source": [
    "To make a prediction with the model, we'll import the model's class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba4a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.model import InsuranceChargesModel\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930eeb14",
   "metadata": {},
   "source": [
    "Now we can instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d25098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceChargesModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e5f44",
   "metadata": {},
   "source": [
    "To make a prediction, we'll need to use the model's input schema class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766a0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insurance_charges_model.prediction.schemas import InsuranceChargesModelInput, \\\n",
    "    SexEnum, RegionEnum\n",
    "\n",
    "model_input = InsuranceChargesModelInput(\n",
    "    age=42, \n",
    "    sex=SexEnum.female,\n",
    "    bmi=24.0,\n",
    "    children=2,\n",
    "    smoker=False,\n",
    "    region=RegionEnum.northwest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f6bcac",
   "metadata": {},
   "source": [
    "The model's input schema is called InsuranceChargesModelInput and it encompasses all of the features required by the model to make a prediction.\n",
    "\n",
    "Now we can make a prediction with the model by calling the predict() method with an instance of the InsuranceChargesModelInput class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d6eb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=8640.78)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d1d02",
   "metadata": {},
   "source": [
    "The model predicts that the charges will be $8640.78.\n",
    "\n",
    "When deploying the model we’ll pretend that the age, sex, bmi, children, smoker, and region fields are not available from the client system that is calling the model. Because of this, we’ll need to add it to the model input by loading the data from the database.\n",
    "\n",
    "We can view input schema of the model as a JSON schema document by calling the .schema() method on the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8938e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelInput',\n",
       " 'description': \"Schema for input of the model's predict method.\",\n",
       " 'type': 'object',\n",
       " 'properties': {'age': {'title': 'Age',\n",
       "   'description': 'Age of primary beneficiary in years.',\n",
       "   'minimum': 18,\n",
       "   'maximum': 65,\n",
       "   'type': 'integer'},\n",
       "  'sex': {'title': 'Sex',\n",
       "   'description': 'Gender of beneficiary.',\n",
       "   'allOf': [{'$ref': '#/definitions/SexEnum'}]},\n",
       "  'bmi': {'title': 'Body Mass Index',\n",
       "   'description': 'Body mass index of beneficiary.',\n",
       "   'minimum': 15.0,\n",
       "   'maximum': 50.0,\n",
       "   'type': 'number'},\n",
       "  'children': {'title': 'Children',\n",
       "   'description': 'Number of children covered by health insurance.',\n",
       "   'minimum': 0,\n",
       "   'maximum': 5,\n",
       "   'type': 'integer'},\n",
       "  'smoker': {'title': 'Smoker',\n",
       "   'description': 'Whether beneficiary is a smoker.',\n",
       "   'type': 'boolean'},\n",
       "  'region': {'title': 'Region',\n",
       "   'description': 'Region where beneficiary lives.',\n",
       "   'allOf': [{'$ref': '#/definitions/RegionEnum'}]}},\n",
       " 'definitions': {'SexEnum': {'title': 'SexEnum',\n",
       "   'description': \"Enumeration for the value of the 'sex' input of the model.\",\n",
       "   'enum': ['male', 'female'],\n",
       "   'type': 'string'},\n",
       "  'RegionEnum': {'title': 'RegionEnum',\n",
       "   'description': \"Enumeration for the value of the 'region' input of the model.\",\n",
       "   'enum': ['southwest', 'southeast', 'northwest', 'northeast'],\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f356c",
   "metadata": {},
   "source": [
    "## Creating the Data Enrichment Decorator\n",
    "\n",
    "A decorator needs to inherit from the MLModelDecorator base class, which requires a specific set of methods and properties be implemented. The decorator that can access PostgreSQL looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726cb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel, create_model\n",
    "import psycopg2\n",
    "from ml_base.decorator import MLModelDecorator\n",
    "from ml_base.ml_model import MLModelSchemaValidationException\n",
    "\n",
    "\n",
    "class PostgreSQLEnrichmentDecorator(MLModelDecorator):\n",
    "    \"\"\"Decorator to do data enrichment using a PostgreSQL database.\"\"\"\n",
    "\n",
    "    def __init__(self, host: str, port: str, username: str, password: str, database: str,\n",
    "                 table: str, index_field_name: str, index_field_type: str,\n",
    "                 enrichment_fields: List[str]) -> None:\n",
    "        # if password has ${}, then replace with environment variable\n",
    "        if password[0:2] == \"${\" and password[-1] == \"}\":\n",
    "            password = os.environ[password[2:-1]]\n",
    "        super().__init__(host=host, port=port, username=username, password=password,\n",
    "                         database=database, table=table, index_field_name=index_field_name,\n",
    "                         index_field_type=index_field_type, enrichment_fields=enrichment_fields)\n",
    "        self.__dict__[\"_connection\"] = None\n",
    "\n",
    "    @property\n",
    "    def input_schema(self) -> BaseModel:\n",
    "        # converting the index field type from a string to a class\n",
    "        try:\n",
    "            index_field_type = __builtins__[self._configuration[\"index_field_type\"]]\n",
    "        except TypeError as e:\n",
    "            index_field_type = __builtins__.__dict__[self._configuration[\"index_field_type\"]]\n",
    "\n",
    "        input_schema = self._model.input_schema\n",
    "\n",
    "        # adding index field to schema because it is required in order to retrieve\n",
    "        # the right record in the database\n",
    "        fields = {\n",
    "            self._configuration[\"index_field_name\"]: (index_field_type, ...)\n",
    "        }\n",
    "        for field_name, schema in input_schema.__fields__.items():\n",
    "            # remove enrichment_fields from schema because they'll be added from the\n",
    "            # database and don't need to be provided by the client\n",
    "            if field_name not in self._configuration[\"enrichment_fields\"]:\n",
    "                if schema.required:\n",
    "                    fields[field_name] = (schema.type_, ...)\n",
    "                else:\n",
    "                    fields[field_name] = (schema.type_, schema.default)\n",
    "\n",
    "        new_input_schema = create_model(\n",
    "            input_schema.__name__,\n",
    "            **fields\n",
    "        )\n",
    "        return new_input_schema\n",
    "\n",
    "    def predict(self, data):\n",
    "        # create a connection to the database, if it doesn't exist already\n",
    "        if self.__dict__[\"_connection\"] is None:\n",
    "            self.__dict__[\"_connection\"] = psycopg2.connect(\n",
    "                host=self._configuration[\"host\"],\n",
    "                port=self._configuration[\"port\"],\n",
    "                database=self._configuration[\"database\"],\n",
    "                user=self._configuration[\"username\"],\n",
    "                password=self._configuration[\"password\"])\n",
    "        cursor = self.__dict__[\"_connection\"].cursor()\n",
    "\n",
    "        # build a SELECT statement using the index_field and the enrichment_fields\n",
    "        enrichment_fields = \", \".join(self._configuration[\"enrichment_fields\"])\n",
    "        sql_statement = \"SELECT {} FROM {} WHERE {} = %s;\".format(\n",
    "            enrichment_fields,\n",
    "            self._configuration[\"table\"],\n",
    "            self._configuration[\"index_field_name\"])\n",
    "\n",
    "        # executing the SELECT statement\n",
    "        cursor.execute(sql_statement,\n",
    "                       (getattr(data, self._configuration[\"index_field_name\"]), ))\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "\n",
    "        if len(records) == 0:\n",
    "            raise ValueError(\"Could not find a record for data enrichment.\")\n",
    "        elif len(records) == 1:\n",
    "            record = records[0]\n",
    "        else:\n",
    "            raise ValueError(\"Query returned more than one record.\")\n",
    "\n",
    "        # creating an instance of the model's input schema using the fields that\n",
    "        # came back from the database and fields that are provided by calling code\n",
    "        input_schema = self.input_schema\n",
    "        enriched_data = {}\n",
    "        for field_name in self._model.input_schema.__fields__.keys():\n",
    "            if field_name == self._configuration[\"index_field_name\"]:\n",
    "                pass\n",
    "            elif field_name in self._configuration[\"enrichment_fields\"]:\n",
    "                field_index = self._configuration[\"enrichment_fields\"].index(field_name)\n",
    "                enriched_data[field_name] = record[field_index]\n",
    "            elif field_name in data.dict().keys():\n",
    "                enriched_data[field_name] = getattr(data, field_name)\n",
    "            else:\n",
    "                raise ValueError(\"Could not find value for field '{}'.\".format(field_name))\n",
    "\n",
    "        # making a prediction with the model, using the enriched fields\n",
    "        try:\n",
    "            enriched_data = self._model.input_schema(**enriched_data)\n",
    "        except ValueError as e:\n",
    "            raise MLModelSchemaValidationException(str(e))\n",
    "        prediction = self._model.predict(data=enriched_data)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            if self.__dict__[\"_connection\"] is not None:\n",
    "                self.__dict__[\"_connection\"].close()\n",
    "        except KeyError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c91f4d",
   "metadata": {},
   "source": [
    "The code is quite long, it is mainly made up of two methods: the input_schema method and the predict method. The input_schema method modifies the model's input schema according to the requirements of the data enrichment we want to do. The predict method is responsible for retrieving the data needed by the model and joining it to the data already provided by the client system.\n",
    "\n",
    "The \\_\\_init\\_\\_() method accepts configuration that is used to customize the way that the decorator finds data in the database. The decorator accepts these parameters:\n",
    "\n",
    "- host: hostname for connecting to the database server\n",
    "- port: port for connecting to the database server\n",
    "- username: username for accessing the database\n",
    "- password: password for accessing the database\n",
    "- table: name of the table in the database where data used for enrichment is found\n",
    "- index_field_name: name of the field used for selecting a record\n",
    "- index_field_type: type of the index field\n",
    "- enrichment_fields: names of the fields that will be added to the data sent to the model to make a prediction\n",
    "\n",
    "The configuration is saved by passing it up to the super class using the super().\\_\\_init\\_\\_() method. The configuration values can then be accessed inside of the decorator instance in the self.\\_configuration attribute, which is a dictionary.\n",
    "\n",
    "When the decorator is applied to a model, it modifies the input_schema of the model. It removes the enrichment_fields from the input schema because these fields are going to be added from the database. This means that the client does not need to provide values for them anymore. It also adds the index_field to the input schema because the decorator needs to use this field to access the correct record in the database table. The index_field is added as a required field in the model’s input_schema because the decorator always needs it.\n",
    "\n",
    "When a prediction request is made to the decorator, it uses the value in the index_field to access the record in the database table. If the decorator finds the record in the table, it selects the enrichment fields and creates a new input object for the model and sends it to the model. If the record is not found, the decorator raises an exception. The index_field is actually not sent to the model at all, it is used purely to access the data needed by the model in the database. If more than one record is returned from the database, an exception is raised.\n",
    "\n",
    "The SQL statement is built dynamically based on the fields required by the model and the index field selected through configuration. For example, if we wanted to do enrichment with all of the input fields of the InsuranceChargesModel, the SELECT statement would look like this:\n",
    "\n",
    "```sql\n",
    "SELECT age, sex, bmi, children, smoker, region\n",
    "FROM clients\n",
    "WHERE ssn = '123-45-6789'\n",
    "```\n",
    "\n",
    "In this case we would be accessing a client record by using their social security number as the index field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9801b",
   "metadata": {},
   "source": [
    "## Decorating the Model\n",
    "\n",
    "To test out the decorator we’ll first instantiate the model object that we want to use with the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30cdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceChargesModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479dc3b",
   "metadata": {},
   "source": [
    "Next, we’ll instantiate the decorator with the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3042be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorator = PostgreSQLEnrichmentDecorator(\n",
    "    host=\"\", \n",
    "    port=\"\",\n",
    "    username=\"\", \n",
    "    password=\"\", \n",
    "    database=\"\", \n",
    "    table=\"\",\n",
    "    index_field_name=\"ssn\", \n",
    "    index_field_type=\"str\", \n",
    "    enrichment_fields=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7944d3",
   "metadata": {},
   "source": [
    "We won't fill in the database details because we don't have a database to connect to yet. However, we can still see how the model's input and output schemas change because of the decorator. In this example, we'll use a client's social security number to uniquely identify records in the datbase table.\n",
    "\n",
    "We can add the model instance to the decorator after it’s been instantiated like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04ba4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorated_model = decorator.set_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561328cc",
   "metadata": {},
   "source": [
    "We can see the decorator and the model objects by printing the reference to the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38a9b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQLEnrichmentDecorator(InsuranceChargesModel)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorated_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434765d",
   "metadata": {},
   "source": [
    "The decorator object is printing out it's own type along with the type of the model that it is decorating.\n",
    "\n",
    "Now we’ll try to use the decorator and the model together by doing a few things. First, we’ll look at the model input schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a39ac26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'ssn': {'title': 'Ssn', 'type': 'string'}},\n",
       " 'required': ['ssn']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorated_model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b46d6a",
   "metadata": {},
   "source": [
    "As we can see, the input schema is not the same as what the model exposed, all of the model’s input fields are now removed because they are being provided by the decorator by accessing the database. The user of the model is not expected to provide a value for those fields. However, there is a new field in the schema, the “ssn” field. This field is used by the decorator to select the correct record in the database.\n",
    "\n",
    "We can also use a few fields from the database and require the client to provide the rest. To do this we'll instantiate the decorator with a few, but not all, of the fields required by the model as enrichment fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020dc0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'ssn': {'title': 'Ssn', 'type': 'string'},\n",
       "  'bmi': {'title': 'Bmi', 'minimum': 15.0, 'maximum': 50.0, 'type': 'number'},\n",
       "  'children': {'title': 'Children',\n",
       "   'minimum': 0,\n",
       "   'maximum': 5,\n",
       "   'type': 'integer'}},\n",
       " 'required': ['ssn']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorator = PostgreSQLEnrichmentDecorator(\n",
    "    host=\"\", \n",
    "    port=\"\",\n",
    "    username=\"\", \n",
    "    password=\"\", \n",
    "    database=\"\", \n",
    "    table=\"\",\n",
    "    index_field_name=\"ssn\", \n",
    "    index_field_type=\"str\", \n",
    "    enrichment_fields=[\"age\", \"sex\", \"smoker\", \"region\"])\n",
    "\n",
    "decorated_model = decorator.set_model(model)\n",
    "\n",
    "decorated_model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d5ab",
   "metadata": {},
   "source": [
    "The model's input schema now requires the fields that are not listed as enrichment fields to be provided by the client. The \"ssn\" field is still added because the decorator needs it in order to retrieve the enrichment fields from the database.\n",
    "\n",
    "Next, we’ll look at the decorated model’s output schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "488805fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelOutput',\n",
       " 'description': \"Schema for output of the model's predict method.\",\n",
       " 'type': 'object',\n",
       " 'properties': {'charges': {'title': 'Charges',\n",
       "   'description': 'Individual medical costs billed by health insurance to customer in US dollars.',\n",
       "   'type': 'number'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_schema = decorated_model.output_schema.schema()\n",
    "\n",
    "output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781efda",
   "metadata": {},
   "source": [
    "The output schema has not changed at all, the decorator does not modify the prediction or the schema of the prediction returned by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261bb69",
   "metadata": {},
   "source": [
    "## Creating a Database\n",
    "\n",
    "Now that we have a model and a decorator that can add data to the input of the model, we need to create a database table to pull data from. To do this we’ll first start a PostgreSQL instance in a local docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951d3e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695889c4c39617d44b158d7307d431180b1358e62ad07bdf26347a85f725468e\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name postgres \\\n",
    "    -p 5432:5432 \\\n",
    "    -e POSTGRES_USER=data_enrichment_user \\\n",
    "    -e POSTGRES_PASSWORD=data_enrichment_password \\\n",
    "    -e POSTGRES_DB=data_enrichment \\\n",
    "    -d postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d4aa6",
   "metadata": {},
   "source": [
    "We can connect to the database by starting a client within the same container and executing a SQL statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc596ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " current_database \r\n",
      "------------------\r\n",
      " data_enrichment\r\n",
      "(1 row)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm \\\n",
    "    --network=\"host\" postgres \\\n",
    "    psql postgresql://data_enrichment_user:data_enrichment_password@127.0.0.1:5432/data_enrichment \\\n",
    "    -c \"SELECT current_database();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4375a",
   "metadata": {},
   "source": [
    "The current database within the server is called \"data_enrichment\" and it was created when the docker image started.\n",
    "\n",
    "Next we'll execute a SQL statement that creates a table within the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1f2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm \\\n",
    "    --network=\"host\" postgres \\\n",
    "    psql postgresql://data_enrichment_user:data_enrichment_password@127.0.0.1:5432/data_enrichment \\\n",
    "    -c \"CREATE TABLE clients ( \\\n",
    "    ssn         varchar(11) PRIMARY KEY, \\\n",
    "    first_name  varchar(30) NOT NULL, \\\n",
    "    last_name   varchar(30) NOT NULL, \\\n",
    "    age         integer     NOT NULL, \\\n",
    "    sex         varchar(6)  NOT NULL, \\\n",
    "    bmi         integer     NOT NULL, \\\n",
    "    children    integer     NOT NULL, \\\n",
    "    smoker      boolean     NOT NULL, \\\n",
    "    region      varchar(10) NOT NULL \\\n",
    ");\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879da5a3",
   "metadata": {},
   "source": [
    "The table has been created, we can see the table schema looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920dc2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Table \"public.clients\"\r\n",
      "   Column   |         Type          | Collation | Nullable | Default \r\n",
      "------------+-----------------------+-----------+----------+---------\r\n",
      " ssn        | character varying(11) |           | not null | \r\n",
      " first_name | character varying(30) |           | not null | \r\n",
      " last_name  | character varying(30) |           | not null | \r\n",
      " age        | integer               |           | not null | \r\n",
      " sex        | character varying(6)  |           | not null | \r\n",
      " bmi        | integer               |           | not null | \r\n",
      " children   | integer               |           | not null | \r\n",
      " smoker     | boolean               |           | not null | \r\n",
      " region     | character varying(10) |           | not null | \r\n",
      "Indexes:\r\n",
      "    \"clients_pkey\" PRIMARY KEY, btree (ssn)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm \\\n",
    "    --network host postgres \\\n",
    "    psql postgresql://data_enrichment_user:data_enrichment_password@127.0.0.1:5432/data_enrichment \\\n",
    "    -c \"\\d clients\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33ec5b",
   "metadata": {},
   "source": [
    "The table has columns for all of the fields that the model requires to make a prediction plus two columns for the first and last name. It also has an index field called “ssn” because we’ll be referencing each record using a fake Social Security number. The ssn field is the unique identifier for each record and is a good way to correlate data from different systems. \n",
    "\n",
    "Then we’ll run a some code that connects to the database and inserts fake data into the table. To do this we'll use the faker package, so we'll need to install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9546bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Faker\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81985caa",
   "metadata": {},
   "source": [
    "To add data to the table, we'll just generate some data for each column in the database table and save it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffcf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "records = list()\n",
    "for _ in range(1000):\n",
    "    sex = fake.random_choices(elements=(\"male\", \"female\"), length=1)[0]\n",
    "    record = {\n",
    "        \"ssn\": fake.ssn(),\n",
    "        \"age\": fake.random_int(min=18, max=80),\n",
    "        \"sex\": sex,\n",
    "        \"bmi\": fake.random_int(min=15, max=50),\n",
    "        \"children\": fake.random_int(min=0, max=5),\n",
    "        \"smoker\": fake.boolean(),\n",
    "        \"region\": fake.random_choices(elements=(\"southwest\", \"southeast\", \"northwest\", \"northeast\"), length=1)[0],\n",
    "        \"first_name\": fake.first_name_male() if sex ==\"male\" else fake.first_name_female(),\n",
    "        \"last_name\": fake.last_name()\n",
    "    }\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c15f8",
   "metadata": {},
   "source": [
    "Notice that each field is generating data that does not necessarily fit the schema of the model. For example, the maximum value allowed by the model for the \"age\" field is 65, but the fake data can go up to 80. We'll use records that do not match the model's schema to test the decorator later.\n",
    "\n",
    "Let's take a look at the first record that matches the model schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "648c3e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ssn': '646-87-1351',\n",
       " 'age': 31,\n",
       " 'sex': 'female',\n",
       " 'bmi': 31,\n",
       " 'children': 1,\n",
       " 'smoker': False,\n",
       " 'region': 'northeast',\n",
       " 'first_name': 'Vickie',\n",
       " 'last_name': 'Anderson'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_record = next(record for record in records if record[\"age\"] <= 65)\n",
    "\n",
    "valid_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54056d6",
   "metadata": {},
   "source": [
    "Now let's find a record that does not fit the model's schema so we can use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90626fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ssn': '361-47-3850',\n",
       " 'age': 72,\n",
       " 'sex': 'male',\n",
       " 'bmi': 34,\n",
       " 'children': 4,\n",
       " 'smoker': False,\n",
       " 'region': 'northeast',\n",
       " 'first_name': 'Michael',\n",
       " 'last_name': 'Pena'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_record = next(record for record in records if record[\"age\"] > 65)\n",
    "\n",
    "invalid_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38929283",
   "metadata": {},
   "source": [
    "We'll use the ssn numbers later to test out the decorator's error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc2041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ssn = valid_record[\"ssn\"]\n",
    "invalid_ssn = invalid_record[\"ssn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50534a1b",
   "metadata": {},
   "source": [
    "Next, we'll put the 1000 fake records generated into the database table that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60438707",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=\"data_enrichment\",\n",
    "    user=\"data_enrichment_user\",\n",
    "    password=\"data_enrichment_password\")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "for record in records:\n",
    "    cursor.execute(\"INSERT INTO clients (ssn, first_name, last_name, age, sex, bmi, children, smoker, region)\"\n",
    "                   \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\",\n",
    "                   (record[\"ssn\"], record[\"first_name\"], record[\"last_name\"], record[\"age\"], record[\"sex\"], \n",
    "                    record[\"bmi\"], record[\"children\"], record[\"smoker\"], record[\"region\"]))\n",
    "    connection.commit()\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5bef0",
   "metadata": {},
   "source": [
    "The database now has a table that has records that we can use to try out the model using the decorator.\n",
    "\n",
    "We'll access a some records to see the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad9b0adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ssn     | first_name | last_name \r\n",
      "-------------+------------+-----------\r\n",
      " 646-87-1351 | Vickie     | Anderson\r\n",
      " 194-94-3733 | Patricia   | Lee\r\n",
      " 709-08-5148 | Seth       | James\r\n",
      " 132-30-5594 | Edward     | Allen\r\n",
      " 096-55-1187 | Mark       | Keith\r\n",
      "(5 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm \\\n",
    "    --network host postgres \\\n",
    "    psql postgresql://data_enrichment_user:data_enrichment_password@127.0.0.1:5432/data_enrichment \\\n",
    "    -c \"SELECT ssn, first_name, last_name FROM clients LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d4745",
   "metadata": {},
   "source": [
    "## Trying out the Decorator\n",
    "\n",
    "Now that we have some data in the database, we can try to make predictions with the decorated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68f0e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorator = PostgreSQLEnrichmentDecorator(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    username=\"data_enrichment_user\", \n",
    "    password=\"data_enrichment_password\", \n",
    "    database=\"data_enrichment\", \n",
    "    table=\"clients\",\n",
    "    index_field_name=\"ssn\", \n",
    "    index_field_type=\"str\", \n",
    "    enrichment_fields=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"])\n",
    "\n",
    "decorated_model = decorator.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b287717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=6416.86)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = decorated_model.input_schema(ssn=valid_ssn)\n",
    "\n",
    "prediction = decorated_model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca13e48",
   "metadata": {},
   "source": [
    "We provided a value for the ssn field and the decorator was able to retrieve the values for the other fields for the model to use.\n",
    "\n",
    "Next, we'll see what happens when we try to do data enrichment with a record that does not exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1bd0fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find a record for data enrichment.\n"
     ]
    }
   ],
   "source": [
    "model_input = decorated_model.input_schema(ssn=\"123-45-6789\")\n",
    "\n",
    "try:\n",
    "    decorated_model.predict(model_input)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6cc8a",
   "metadata": {},
   "source": [
    "The decorator raised a ValueError exception because it could not find the needed record.\n",
    "\n",
    "We can also leave some fields for the client of the model to provide and pull all other fields from the database. We just need to instantiate the decorator a little differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fd65b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorator = PostgreSQLEnrichmentDecorator(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\", \n",
    "    username=\"data_enrichment_user\", \n",
    "    password=\"data_enrichment_password\", \n",
    "    database=\"data_enrichment\", \n",
    "    table=\"clients\",\n",
    "    index_field_name=\"ssn\", \n",
    "    index_field_type=\"str\", \n",
    "    enrichment_fields=[\"age\", \"sex\", \"bmi\", \"region\"])\n",
    "\n",
    "decorated_model = decorator.set_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b85b7",
   "metadata": {},
   "source": [
    "To see which fields are now required by the model, we'll take a look at the input schema of the decorated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4774712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'InsuranceChargesModelInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'ssn': {'title': 'Ssn', 'type': 'string'},\n",
       "  'children': {'title': 'Children',\n",
       "   'minimum': 0,\n",
       "   'maximum': 5,\n",
       "   'type': 'integer'},\n",
       "  'smoker': {'title': 'Smoker', 'type': 'boolean'}},\n",
       " 'required': ['ssn']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema = decorated_model.input_schema.schema()\n",
    "\n",
    "input_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b657d2",
   "metadata": {},
   "source": [
    "The decorator has removed the age, sex, bmi, and region fields from the input schema. It has left the smoker and children fields in place, and it has added the ssn field as we expected.\n",
    "\n",
    "Now we can try the decorator with this new input schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51d4246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsuranceChargesModelOutput(charges=6123.85)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = decorated_model.input_schema(ssn=valid_ssn, children=2, smoker=False)\n",
    "\n",
    "prediction = decorated_model.predict(model_input)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d500c",
   "metadata": {},
   "source": [
    "The decorator was able to bring in the values for the missing fields from the database and join them to the fields provided by the client in order to make a prediction. \n",
    "\n",
    "Lastly, we'll select a client record in the database that does not meet the schema requirements of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cb263a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for InsuranceChargesModelInput\n",
      "age\n",
      "  ensure this value is less than or equal to 65 (type=value_error.number.not_le; limit_value=65)\n"
     ]
    }
   ],
   "source": [
    "model_input = decorated_model.input_schema(ssn=invalid_ssn, children=2, smoker=False)\n",
    "\n",
    "try:\n",
    "    prediction = decorated_model.predict(model_input)\n",
    "except MLModelSchemaValidationException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f1f88",
   "metadata": {},
   "source": [
    "Because we put some records in the database that do not meet the input schema of the model a ValueError was raised inside of the decorator instance. The record had an age value that is above 65, which the model cannot predict with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d9a84",
   "metadata": {},
   "source": [
    "## Adding a Decorator to a Deployed Model\n",
    "\n",
    "Now that we have a model and a decorator, we can combine them together into a service that is able to make predictions and also do data enrichment. To do this, we won't need to write any extra code, we can leverage the [rest_model_service package](https://pypi.org/project/rest-model-service/) to provide the RESTful API for the service. You can learn more about the package in [this blog post](https://www.tekhnoal.com/rest-model-service.html).\n",
    "\n",
    "To install the package, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "202ecd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rest_model_service\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552bdfb",
   "metadata": {},
   "source": [
    "To create a service for our model, all that is needed is that we add a YAML configuration file to the project. The configuration file looks like this:\n",
    "\n",
    "```yaml\n",
    "service_title: Insurance Charges Model Service\n",
    "models:\n",
    "  - qualified_name: insurance_charges_model\n",
    "    class_path: insurance_charges_model.prediction.model.InsuranceChargesModel\n",
    "    create_endpoint: true\n",
    "    decorators:\n",
    "      - class_path: data_enrichment.postgresql.PostgreSQLEnrichmentDecorator\n",
    "        configuration:\n",
    "          host: \"localhost\"\n",
    "          port: \"5432\"\n",
    "          username: \"data_enrichment_user\"\n",
    "          password: \"data_enrichment_password\"\n",
    "          database: \"data_enrichment\"\n",
    "          table: \"clients\"\n",
    "          index_field_name: \"ssn\"\n",
    "          index_field_type: \"str\"\n",
    "          enrichment_fields:\n",
    "            - \"age\"\n",
    "            - \"sex\"\n",
    "            - \"bmi\"\n",
    "            - \"children\"\n",
    "            - \"smoker\"\n",
    "            - \"region\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8cf552",
   "metadata": {},
   "source": [
    "The service_title field is the name of the service as it will appear in the documentation. The models field is an array that contains the details of the models we would like to deploy in the service. The class_path points at the MLModel class that implement's the model's prediction logic. The decorators field contains the details of the decorators that we want to attach to the model instance. In this case, we want to use the PostgreSQLEnrichmentDecorator decorator class with the configuration we've used for local testing.\n",
    "\n",
    "Using the configuration file, we're able to create an OpenAPI specification file for the model service by executing these commands:\n",
    "\n",
    "```bash\n",
    "export PYTHONPATH=./\n",
    "export REST_CONFIG=./configuration/rest_config.yaml\n",
    "generate_openapi --output_file=\"service_contract.yaml\"\n",
    "```\n",
    "\n",
    "The service_contract.yaml file will be generated and it will contain the specification that was generated for the model service. The insurance_charges_model endpoint is the one we'll call to make predictions with the model. The model's input and output schemas were automatically extracted and added to the specification. If you inspect the contract, you'll find that the enrichment fields are not part of the input schema because they are being removed by the enrichment decorator. The ssn field has been added to the contract because it is needed to do data enrichment.\n",
    "\n",
    "To run the service locally, execute these commands:\n",
    "\n",
    "```bash\n",
    "uvicorn rest_model_service.main:app --reload\n",
    "```\n",
    "\n",
    "The service should come up and can be accessed in a web browser at http://127.0.0.1:8000. When you access that URL you will be redirected to the documentation page that is generated by the FastAPI package:\n",
    "\n",
    "![FastAPI Documentation](fastapi_documentation.png)\n",
    "![FastAPI Documentation]({attach}fastapi_documentation.png){ width=100% }\n",
    "\n",
    "The documentation allows you to make requests against the API in order to try it out. Here's a prediction request against the insurance charges model:\n",
    "\n",
    "![Prediction Request](prediction_request.png)\n",
    "![Prediction Request]({attach}prediction_request.png){ width=100% }\n",
    "\n",
    "And the prediction result:\n",
    "\n",
    "![Prediction Result](prediction_result.png)\n",
    "![Prediction Result]({attach}prediction_result.png){ width=100% }\n",
    "\n",
    "By using the MLModel base class provided by the ml_base package and the REST service framework provided by the rest_model_service package we're able to quickly stand up a service to host the model. The decorator that we want to test can also be added to the model through configuration, including all of its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f11a3b",
   "metadata": {},
   "source": [
    "## Deploying the Model\n",
    "\n",
    "Now that we have a working model and model service, we'll need to deploy it somewhere. We'll start by deploying the service locally. Once we have the service and database working locally, we'll deploy everything to the cloud using DigitalOcean's managed kubernetes service.\n",
    "\n",
    "### Creating a Docker Image\n",
    "\n",
    "Before moving forward, let's create a docker image and run it locally. The docker image is generated using instructions in the Dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "MAINTAINER Brian Schmidt \"6666331+schmidtbri@users.noreply.github.com\"\n",
    "\n",
    "WORKDIR ./service\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get --assume-yes install git\n",
    "\n",
    "COPY ./data_enrichment ./data_enrichment\n",
    "COPY ./configuration ./configuration\n",
    "COPY ./LICENSE ./LICENSE\n",
    "COPY ./requirements.txt ./requirements.txt\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "CMD [\"uvicorn\", \"rest_model_service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\n",
    "```\n",
    "\n",
    "The Dockerfile is used by this command to create a docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9259851",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t insurance_charges_model_service:0.1.0 ..\\\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f9233",
   "metadata": {},
   "source": [
    "To make sure everything worked as expected, we'll look through the docker images in our system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e319c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_charges_model_service   0.1.0     f5b85418ebc7   2 days ago     1.53GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep insurance_charges_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaac8f4",
   "metadata": {},
   "source": [
    "The insurance_charges_model_service image is listed. Next, we'll start the image to see if everything is working as expected. However, we need to connect the docker containers to the same network first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50958f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcfa5ed0334b609c6f553caac67375c0571438f4541d75d63be79638a6e300f7\r\n"
     ]
    }
   ],
   "source": [
    "!docker network create data-enrichment-network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed3bb6",
   "metadata": {},
   "source": [
    "Next, we'll connect the running postgres image to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14d38429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker network connect data-enrichment-network postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e66e3",
   "metadata": {},
   "source": [
    "Now we can start the service docker image connected to the same network as the postgres container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa46b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6e1bc98063053f9260e078fb4bef3e36637bb84e73b04441791e2c75fd0ad833\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -d \\\n",
    "    -p 8000:8000 \\\n",
    "    --net data-enrichment-network \\\n",
    "    -e REST_CONFIG=./configuration/local_rest_config.yaml \\\n",
    "    --name insurance_charges_model_service \\\n",
    "    insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d91369",
   "metadata": {},
   "source": [
    "Notice that we're using a different configuration file that has a different hostname for the postgres instance. The postgres image is not accesible from localhost inside of the network so we needed to have the hostname \"postgres\" in the configuration.\n",
    "\n",
    "The service should be accessible on port 8000 of localhost, so we'll try to make a prediction using the curl command running inside of a container connected to the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eafdb89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":6416.86}"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm \\\n",
    "    --net data-enrichment-network \\\n",
    "    curlimages/curl \\\n",
    "    curl -X 'POST' \\\n",
    "    'http://insurance_charges_model_service:8000/api/models/insurance_charges_model/prediction' \\\n",
    "    -H 'accept: application/json' \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -d '{\"ssn\": \"646-87-1351\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6689c0",
   "metadata": {},
   "source": [
    "The model predicted that the insurance charges will be $6416.86 for the person whose SSN is 646-87-1351."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4317480",
   "metadata": {},
   "source": [
    "We're done with the service and the database so we'll shut down the docker containers and the docker network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32d2324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres\n",
      "postgres\n",
      "insurance_charges_model_service\n",
      "insurance_charges_model_service\n",
      "data-enrichment-network\n"
     ]
    }
   ],
   "source": [
    "!docker kill postgres\n",
    "!docker rm postgres\n",
    "\n",
    "!docker kill insurance_charges_model_service\n",
    "!docker rm insurance_charges_model_service\n",
    "\n",
    "!docker network rm data-enrichment-network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a37672",
   "metadata": {},
   "source": [
    "### Setting up Digital Ocean\n",
    "\n",
    "In order to deploy the model service to a DigitalOcean kubernetes cluster, we'll need to connect to the DigitalOcean API. \n",
    "\n",
    "In this section we'll be using the doctl command line utility which will help us to interact with the Digital Ocean Kubernetes service. We followed [these instructions](https://docs.digitalocean.com/reference/doctl/how-to/install/) to install the doctl utility. Before we can do anything with the Digital Ocean API, we need to authenticate, so we created an API token by following [these instructions](https://docs.digitalocean.com/reference/api/create-personal-access-token/). Once we have the token we can add it to the doctl utility by creating a new authentication context with this command:\n",
    "\n",
    "```bash\n",
    "doctl auth init --context model-services-context\n",
    "```\n",
    "\n",
    "The command will ask for the token that we generated on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2226fa2",
   "metadata": {},
   "source": [
    "The command creates a new context called \"model-services-context\" that we'll use to interact with the Digital Ocean API. The command asks for the API token we generated and saves it into the configuration file of the tool. To make sure that the context was created correctly and is the current context, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12ebdd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\r\n",
      "model-services-context (current)\r\n"
     ]
    }
   ],
   "source": [
    "!doctl auth list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88020a",
   "metadata": {},
   "source": [
    "The newly created context should be listed and have \"(current)\" by its name. If the context we created is not the current context, we can switch to it with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15b1125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using context [model-services-context] by default\r\n"
     ]
    }
   ],
   "source": [
    "!doctl auth switch --context model-services-context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef51f6",
   "metadata": {},
   "source": [
    "Now that we have the credentials necessary, we can start creating the infrastructure for our deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6e0a4",
   "metadata": {},
   "source": [
    "### Creating the Kubernetes Cluster\n",
    "\n",
    "To create the kubernetes cluster and supporting infrastructure, we'll use [Terraform](https://www.terraform.io/). Terraform is an Infrastructure as Code (IaC) tool that will allow us to declaratively create our infrastructure in configuration files, and then create, manage, and destroy it with simple commands. The command line Terraform tool can be installed by following [these intructions](https://learn.hashicorp.com/tutorials/terraform/install-cli).\n",
    "\n",
    "We wont be doing a deep dive into Terraform for this blog post because it would make the post too long. The Terraform module that we'll install is in the source code attached to this post, in the \"terraform\" folder. \n",
    "\n",
    "To begin, we'll switch into the terraform folder and add our API token to an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b01232f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../terraform\n",
    "\n",
    "%env DIGITALOCEAN_TOKEN=dop_v1_c857bb7bb4bed089000125513c49f642f03401253ec09178c41f94df665312a4\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc09c68",
   "metadata": {},
   "source": [
    "Next, we'll initialize the Terraform environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5dae1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "- Finding latest version of hashicorp/kubernetes...\n",
      "- Finding digitalocean/digitalocean versions matching \"~> 2.0\"...\n",
      "- Installing hashicorp/kubernetes v2.11.0...\n",
      "- Installed hashicorp/kubernetes v2.11.0 (signed by HashiCorp)\n",
      "- Installing digitalocean/digitalocean v2.19.0...\n",
      "- Installed digitalocean/digitalocean v2.19.0 (signed by a HashiCorp partner, key ID \u001b[0m\u001b[1mF82037E524B9C0E8\u001b[0m\u001b[0m)\n",
      "\n",
      "Partner and community providers are signed by their developers.\n",
      "If you'd like to know more about provider signing, you can read about it here:\n",
      "https://www.terraform.io/docs/cli/plugins/signing.html\n",
      "\n",
      "Terraform has created a lock file \u001b[1m.terraform.lock.hcl\u001b[0m to record the provider\n",
      "selections it made above. Include this file in your version control repository\n",
      "so that Terraform can guarantee to make the same selections by default when\n",
      "you run \"terraform init\" in the future.\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!terraform init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68afcc01",
   "metadata": {},
   "source": [
    "The terraform environment is now initialized and stored in the terraform folder. We can now create a plan for the deployment of the resources.\n",
    "\n",
    "The plan command required an input variable called \"project_name\" which allows the resources to have a shared naming convention. We provided the value through the command line option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a15c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Terraform used the selected providers to generate the following execution plan.\r\n",
      "Resource actions are indicated with the following symbols:\r\n",
      "  \u001b[32m+\u001b[0m create\r\n",
      "\u001b[0m\r\n",
      "Terraform will perform the following actions:\r\n",
      "\r\n",
      "\u001b[1m  # digitalocean_container_registry.container_registry\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_container_registry\" \"container_registry\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m               = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                     = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m                   = \"model-services-registry\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m                 = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mserver_url\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstorage_usage_bytes\u001b[0m\u001b[0m    = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msubscription_tier_slug\u001b[0m\u001b[0m = \"basic\"\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # digitalocean_container_registry_docker_credentials.registry_credentials\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_container_registry_docker_credentials\" \"registry_credentials\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcredential_expiration_time\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdocker_credentials\u001b[0m\u001b[0m         = (sensitive value)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mexpiry_seconds\u001b[0m\u001b[0m             = 1576800000\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                         = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_name\u001b[0m\u001b[0m              = \"model-services-registry\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mwrite\u001b[0m\u001b[0m                      = true\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # digitalocean_kubernetes_cluster.cluster\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_cluster\" \"cluster\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_subnet\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m     = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m       = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mha\u001b[0m\u001b[0m             = false\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mipv4_address\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mkube_config\u001b[0m\u001b[0m    = (sensitive value)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m           = \"model-services-cluster\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m         = \"nyc1\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mservice_subnet\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstatus\u001b[0m\u001b[0m         = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msurge_upgrade\u001b[0m\u001b[0m  = true\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m     = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m            = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mversion\u001b[0m\u001b[0m        = \"1.22.8-do.1\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mvpc_uuid\u001b[0m\u001b[0m       = (known after apply)\r\n",
      "\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0mmaintenance_policy {\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mday\u001b[0m\u001b[0m        = \"sunday\"\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mduration\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstart_time\u001b[0m\u001b[0m = \"04:00\"\r\n",
      "        }\r\n",
      "\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0mnode_pool {\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"model-services-cluster-worker-pool\"\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 3\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-2vcpu-2gb\"\r\n",
      "        }\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # digitalocean_vpc.cluster_vpc\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_vpc\" \"cluster_vpc\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdefault\u001b[0m\u001b[0m    = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mip_range\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"model-services-vpc\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m     = \"nyc1\"\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m        = (known after apply)\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[1m  # kubernetes_secret.cluster_registry_crendentials\u001b[0m will be created\u001b[0m\u001b[0m\r\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"kubernetes_secret\" \"cluster_registry_crendentials\" {\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdata\u001b[0m\u001b[0m = (sensitive value)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m   = (known after apply)\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mtype\u001b[0m\u001b[0m = \"kubernetes.io/dockerconfigjson\"\r\n",
      "\r\n",
      "      \u001b[32m+\u001b[0m \u001b[0mmetadata {\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mgeneration\u001b[0m\u001b[0m       = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m             = \"docker-cfg\"\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnamespace\u001b[0m\u001b[0m        = \"default\"\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mresource_version\u001b[0m\u001b[0m = (known after apply)\r\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0muid\u001b[0m\u001b[0m              = (known after apply)\r\n",
      "        }\r\n",
      "    }\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mPlan:\u001b[0m 5 to add, 0 to change, 0 to destroy.\r\n",
      "\u001b[0m\u001b[0m\r\n",
      "\u001b[1mChanges to Outputs:\u001b[0m\u001b[0m\r\n",
      "  \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mkubernetes_cluster_id\u001b[0m\u001b[0m = (known after apply)\r\n",
      "  \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_endpoint\u001b[0m\u001b[0m     = (known after apply)\r\n",
      "\u001b[90m\r\n",
      "───────────────────────────────────────────────────────────────────────────────\u001b[0m\r\n",
      "\r\n",
      "Note: You didn't use the -out option to save this plan, so Terraform can't\r\n",
      "guarantee to take exactly these actions if you run \"terraform apply\" now.\r\n"
     ]
    }
   ],
   "source": [
    "!terraform plan -var=\"project_name=model-services\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6c0e8",
   "metadata": {},
   "source": [
    "The output of the plan command gives us a list of the resources that will be created. These resources are:\n",
    "\n",
    "- docker registry, used to deploy images to the cluster\n",
    "- docker registry credentials, used to allow access to the images from the cluster\n",
    "- VPC, a private network for the cluster nodes\n",
    "- kubernetes cluster, used to host the services\n",
    "- kubernetes secret, to hold the docker registry credentials so that the cluster can load images from the docker registry\n",
    "\n",
    "We can create the resources with the apply command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc78de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Terraform used the selected providers to generate the following execution plan.\n",
      "Resource actions are indicated with the following symbols:\n",
      "  \u001b[32m+\u001b[0m create\n",
      "\u001b[0m\n",
      "Terraform will perform the following actions:\n",
      "\n",
      "\u001b[1m  # digitalocean_container_registry.container_registry\u001b[0m will be created\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_container_registry\" \"container_registry\" {\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m             = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m               = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                     = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m                   = \"model-services-registry\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m                 = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mserver_url\u001b[0m\u001b[0m             = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstorage_usage_bytes\u001b[0m\u001b[0m    = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msubscription_tier_slug\u001b[0m\u001b[0m = \"basic\"\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_container_registry_docker_credentials.registry_credentials\u001b[0m will be created\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_container_registry_docker_credentials\" \"registry_credentials\" {\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcredential_expiration_time\u001b[0m\u001b[0m = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdocker_credentials\u001b[0m\u001b[0m         = (sensitive value)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mexpiry_seconds\u001b[0m\u001b[0m             = 1576800000\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                         = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_name\u001b[0m\u001b[0m              = \"model-services-registry\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mwrite\u001b[0m\u001b[0m                      = true\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_kubernetes_cluster.cluster\u001b[0m will be created\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_cluster\" \"cluster\" {\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_subnet\u001b[0m\u001b[0m = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m     = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m       = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mha\u001b[0m\u001b[0m             = false\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m             = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mipv4_address\u001b[0m\u001b[0m   = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mkube_config\u001b[0m\u001b[0m    = (sensitive value)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m           = \"model-services-cluster\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m         = \"nyc1\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mservice_subnet\u001b[0m\u001b[0m = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstatus\u001b[0m\u001b[0m         = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msurge_upgrade\u001b[0m\u001b[0m  = true\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m     = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m            = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mversion\u001b[0m\u001b[0m        = \"1.22.8-do.1\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mvpc_uuid\u001b[0m\u001b[0m       = (known after apply)\n",
      "\n",
      "      \u001b[32m+\u001b[0m \u001b[0mmaintenance_policy {\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mday\u001b[0m\u001b[0m        = \"sunday\"\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mduration\u001b[0m\u001b[0m   = (known after apply)\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mstart_time\u001b[0m\u001b[0m = \"04:00\"\n",
      "        }\n",
      "\n",
      "      \u001b[32m+\u001b[0m \u001b[0mnode_pool {\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = (known after apply)\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = (known after apply)\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"model-services-cluster-worker-pool\"\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 3\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = (known after apply)\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-2vcpu-2gb\"\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_vpc.cluster_vpc\u001b[0m will be created\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"digitalocean_vpc\" \"cluster_vpc\" {\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdefault\u001b[0m\u001b[0m    = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mip_range\u001b[0m\u001b[0m   = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"model-services-vpc\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m     = \"nyc1\"\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m        = (known after apply)\n",
      "    }\n",
      "\n",
      "\u001b[1m  # kubernetes_secret.cluster_registry_crendentials\u001b[0m will be created\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"kubernetes_secret\" \"cluster_registry_crendentials\" {\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mdata\u001b[0m\u001b[0m = (sensitive value)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m   = (known after apply)\n",
      "      \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mtype\u001b[0m\u001b[0m = \"kubernetes.io/dockerconfigjson\"\n",
      "\n",
      "      \u001b[32m+\u001b[0m \u001b[0mmetadata {\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mgeneration\u001b[0m\u001b[0m       = (known after apply)\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m             = \"docker-cfg\"\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mnamespace\u001b[0m\u001b[0m        = \"default\"\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mresource_version\u001b[0m\u001b[0m = (known after apply)\n",
      "          \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0muid\u001b[0m\u001b[0m              = (known after apply)\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[0m\u001b[1mPlan:\u001b[0m 5 to add, 0 to change, 0 to destroy.\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[1mChanges to Outputs:\u001b[0m\u001b[0m\n",
      "  \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mkubernetes_cluster_id\u001b[0m\u001b[0m = (known after apply)\n",
      "  \u001b[32m+\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_endpoint\u001b[0m\u001b[0m     = (known after apply)\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry.container_registry: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Creation complete after 1s [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry.container_registry: Creation complete after 5s [id=model-services-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry_docker_credentials.registry_credentials: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry_docker_credentials.registry_credentials: Creation complete after 0s [id=model-services-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [1m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [1m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [1m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [1m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [1m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [1m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [2m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [2m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [2m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [2m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [2m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [2m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [3m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [3m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [3m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [3m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [3m40s elapsed]\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [3m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [4m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [4m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [4m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [4m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [4m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [4m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [5m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [5m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [5m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [5m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [5m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [5m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [6m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [6m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [6m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [6m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [6m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Still creating... [6m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Creation complete after 6m53s [id=7eda057c-501f-414c-ad36-e4a75feac4e0]\u001b[0m\n",
      "\u001b[0m\u001b[1mkubernetes_secret.cluster_registry_crendentials: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mkubernetes_secret.cluster_registry_crendentials: Creation complete after 1s [id=default/docker-cfg]\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 5 added, 0 changed, 0 destroyed.\n",
      "\u001b[0m\u001b[0m\u001b[1m\u001b[32m\n",
      "Outputs:\n",
      "\n",
      "\u001b[0mkubernetes_cluster_id = \"7eda057c-501f-414c-ad36-e4a75feac4e0\"\n",
      "registry_endpoint = \"registry.digitalocean.com/model-services-registry\"\n"
     ]
    }
   ],
   "source": [
    "!terraform apply -var=\"project_name=model-services\" -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a358f62",
   "metadata": {},
   "source": [
    "The terraform stack returned the id of the cluster that was created. We'll need this id to connect to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91397cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/data-enrichment-for-ml-models\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6e437",
   "metadata": {},
   "source": [
    "### Pushing the Image\n",
    "\n",
    "Now that we have a registry, we need to add credentials to our local docker daemon in order to be able to upload images, to do that we'll use this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b3fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Docker in to registry.digitalocean.com\r\n"
     ]
    }
   ],
   "source": [
    "!doctl registry login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19c113",
   "metadata": {},
   "source": [
    "In order to upload the image, we need to tag it with the URL of the DO registry we created. The URL of the registry was an output of the terraform module we just created above. The docker tag command looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbbd43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag insurance_charges_model_service:0.1.0 registry.digitalocean.com/model-services-registry/insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8988f86",
   "metadata": {},
   "source": [
    "Now we can push the image to the DigitalOcean docker registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb07cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [registry.digitalocean.com/model-services-registry/insurance_charges_model_service]\n",
      "\n",
      "\u001b[1B4e8c730f: Preparing \n",
      "\u001b[1B262abd28: Preparing \n",
      "\u001b[1B103cfdc5: Preparing \n",
      "\u001b[1Be6d9a4d6: Preparing \n",
      "\u001b[1Ba89df31c: Preparing \n",
      "\u001b[1B3bc716a2: Preparing \n",
      "\u001b[1Bb9727396: Preparing \n",
      "\u001b[1B7bf074b6: Preparing \n",
      "\u001b[1B85df8c54: Preparing \n",
      "\u001b[1Bafbe089a: Preparing \n",
      "\u001b[1B90f11bed: Preparing \n",
      "\u001b[1B50a1245f: Preparing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[13Be8c730f: Pushing  426.5MB/1.3GBMB11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[13A\u001b[2K\u001b[9A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[2A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[8A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[13Be8c730f: Pushed   1.311GB/1.3GB\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2KPushing  1.256GB/1.3GB\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K0.1.0: digest: sha256:bb93c997c3190a1465b38987fd76e0b7c9882d444a4969d57c347fe4017d51c5 size: 3044\n"
     ]
    }
   ],
   "source": [
    "!docker push registry.digitalocean.com/model-services-registry/insurance_charges_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaae2af",
   "metadata": {},
   "source": [
    "### Accessing the Kubernetes Cluster\n",
    "\n",
    "To access the cluster, doctl has another option that will set up the kubectl tool for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c979e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mNotice\u001b[0m: Adding cluster credentials to kubeconfig file found in \"/Users/brian/.kube/config\"\r\n",
      "\u001b[32mNotice\u001b[0m: Setting current-context to do-nyc1-model-services-cluster\r\n"
     ]
    }
   ],
   "source": [
    "!doctl kubernetes cluster kubeconfig save 7eda057c-501f-414c-ad36-e4a75feac4e0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c70751",
   "metadata": {},
   "source": [
    "The unique identifier is for the cluster that was just created and is returned by the previous command. When the command finishes, the current kubectl context should be switched to the newly created cluster. To list the contexts in kubectl, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22edc047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT   NAME                             CLUSTER                          AUTHINFO                               NAMESPACE\r\n",
      "*         do-nyc1-model-services-cluster   do-nyc1-model-services-cluster   do-nyc1-model-services-cluster-admin   \r\n",
      "          minikube                         minikube                         minikube                               \r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config get-contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e7661",
   "metadata": {},
   "source": [
    "A listing of the contexts currently in the kubectl configuration should appear, and there should be a star next to the new cluster's context. To make sure everything is working we can get a list of the nodes in the cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8684192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       STATUS   ROLES    AGE   VERSION\r\n",
      "model-services-cluster-worker-pool-crmkf   Ready    <none>   55m   v1.22.8\r\n",
      "model-services-cluster-worker-pool-crmkx   Ready    <none>   55m   v1.22.8\r\n",
      "model-services-cluster-worker-pool-crmky   Ready    <none>   55m   v1.22.8\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a61264",
   "metadata": {},
   "source": [
    "### Creating a Kubernetes Namespace\n",
    "\n",
    "Now that we have a cluster and are connected to it, we'll create a namespace to hold the resources for our model deployment. The resource definition is in the kubernetes/namespace.yml file. To apply the manifest to the cluster, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6dadebd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/model-services created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f kubernetes/namespace.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f44b85",
   "metadata": {},
   "source": [
    "To take a look at the namespaces, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d45c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS   AGE\r\n",
      "default           Active   164m\r\n",
      "kube-node-lease   Active   164m\r\n",
      "kube-public       Active   164m\r\n",
      "kube-system       Active   164m\r\n",
      "model-services    Active   2s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f991c75",
   "metadata": {},
   "source": [
    "The new namespace should appear in the listing along with other namespaces created by default by the system. To use the new namespace for the rest of the operations, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83ed98df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"do-nyc1-model-services-cluster\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context --current --namespace=model-services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcef9b4",
   "metadata": {},
   "source": [
    "### Creating a Database\n",
    "\n",
    "To create a PostgreSQL database instance in Kubernetes, we'll use the [bitnami helm chart](https://github.com/bitnami/charts/tree/master/bitnami/postgresql). \n",
    "\n",
    "Helm charts are packaged applications that can be easily installed on a Kubernetes cluster. To install PostgreSQL we'll first add the bitnami helm repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89b93d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bitnami\" has been added to your repositories\r\n"
     ]
    }
   ],
   "source": [
    "!helm repo add bitnami https://charts.bitnami.com/bitnami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82a59f",
   "metadata": {},
   "source": [
    "Now we can apply the PostgreSQL chart to the current cluster and namespace with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b235c529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: postgres\r\n",
      "LAST DEPLOYED: Sun May  1 23:36:50 2022\r\n",
      "NAMESPACE: model-services\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "TEST SUITE: None\r\n",
      "NOTES:\r\n",
      "CHART NAME: postgresql\r\n",
      "CHART VERSION: 11.1.25\r\n",
      "APP VERSION: 14.2.0\r\n",
      "\r\n",
      "** Please be patient while the chart is being deployed **\r\n",
      "\r\n",
      "PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:\r\n",
      "\r\n",
      "    postgres-postgresql.model-services.svc.cluster.local - Read/Write connection\r\n",
      "\r\n",
      "To get the password for \"postgres\" run:\r\n",
      "\r\n",
      "    export POSTGRES_PASSWORD=$(kubectl get secret --namespace model-services postgres-postgresql -o jsonpath=\"{.data.postgres-password}\" | base64 --decode)\r\n",
      "\r\n",
      "To connect to your database run the following command:\r\n",
      "\r\n",
      "    kubectl run postgres-postgresql-client --rm --tty -i --restart='Never' --namespace model-services --image docker.io/bitnami/postgresql:14.2.0-debian-10-r77 --env=\"PGPASSWORD=$POSTGRES_PASSWORD\" \\\r\n",
      "      --command -- psql --host postgres-postgresql -U postgres -d postgres -p 5432\r\n",
      "\r\n",
      "    > NOTE: If you access the container using bash, make sure that you execute \"/opt/bitnami/scripts/entrypoint.sh /bin/bash\" in order to avoid the error \"psql: local user with ID 1001} does not exist\"\r\n",
      "\r\n",
      "To connect to your database from outside the cluster execute the following commands:\r\n",
      "\r\n",
      "    kubectl port-forward --namespace model-services svc/postgres-postgresql 5432:5432 &\r\n",
      "    PGPASSWORD=\"$POSTGRES_PASSWORD\" psql --host 127.0.0.1 -U postgres -d postgres -p 5432\r\n"
     ]
    }
   ],
   "source": [
    "!helm install postgres bitnami/postgresql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0752c7",
   "metadata": {},
   "source": [
    "The output of the helm chart contains some info about the deployment that we'll need later. The DNS name of the new PostgreSQL service is used in the configuration of the decorator.\n",
    "\n",
    "We can view the newly created database instance by looking for the pods that are hosting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c074ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    READY   STATUS    RESTARTS   AGE\r\n",
      "postgres-postgresql-0   1/1     Running   0          104s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a6670",
   "metadata": {},
   "source": [
    "To access the database, we'll need to get the password created by the helm chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e43b5fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaF0fhHrRj"
     ]
    }
   ],
   "source": [
    "!kubectl get secret postgres-postgresql -o jsonpath=\"{.data.postgres-password}\" | base64 --decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aafa3b",
   "metadata": {},
   "source": [
    "We can test the database by executing a simple SELECT statement from another pod in the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9545e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " current_database \n",
      "------------------\n",
      " postgres\n",
      "(1 row)\n",
      "\n",
      "pod \"postgres-postgresql-client\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl run postgres-postgresql-client --rm --tty -i \\\n",
    "    --restart='Never' \\\n",
    "    --image docker.io/bitnami/postgresql:14.2.0-debian-10-r77 \\\n",
    "    --command -- psql postgresql://postgres:SaF0fhHrRj@postgres-postgresql:5432/postgres \\\n",
    "                -c \"SELECT current_database();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96fe44",
   "metadata": {},
   "source": [
    "To create a table in the database, we'll execute a SQL command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a39170a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE\n",
      "pod \"postgres-postgresql-client\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl run postgres-postgresql-client --rm --tty -i \\\n",
    "    --restart='Never' \\\n",
    "    --image docker.io/bitnami/postgresql:14.2.0-debian-10-r77 \\\n",
    "    --command -- psql postgresql://postgres:SaF0fhHrRj@postgres-postgresql:5432/postgres \\\n",
    "                -c \"CREATE TABLE clients ( \\\n",
    "                    ssn         varchar(11) PRIMARY KEY, \\\n",
    "                    first_name  varchar(30) NOT NULL, \\\n",
    "                    last_name   varchar(30) NOT NULL, \\\n",
    "                    age         integer     NOT NULL, \\\n",
    "                    sex         varchar(6)  NOT NULL, \\\n",
    "                    bmi         integer     NOT NULL, \\\n",
    "                    children    integer     NOT NULL, \\\n",
    "                    smoker      boolean     NOT NULL, \\\n",
    "                    region      varchar(10) NOT NULL);\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944476f6",
   "metadata": {},
   "source": [
    "Next, we'll add some data to the table using the same code as we used for the local docker PostgreSQL instance. Before that, we'll need to connect to the instance using using port forwarding. Port forwarding is a simple way to connect to a pod running in the cluster from the local environment, it simply forwards all traffic from a local port to a remote port in the pod.\n",
    "\n",
    "To start port forwarding, execute this command:\n",
    "\n",
    "```bash\n",
    "kubectl port-forward svc/postgres-postgresql 5432:5432\n",
    "```\n",
    "\n",
    "Now we can execute the python code that will add the data to the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffa310b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"SaF0fhHrRj\")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "for record in records:\n",
    "    cursor.execute(\"INSERT INTO clients (ssn, first_name, last_name, age, sex, bmi, children, smoker, region)\"\n",
    "                   \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\",\n",
    "                   (record[\"ssn\"], record[\"first_name\"], record[\"last_name\"], record[\"age\"], record[\"sex\"], \n",
    "                    record[\"bmi\"], record[\"children\"], record[\"smoker\"], record[\"region\"]))\n",
    "    connection.commit()\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a80660",
   "metadata": {},
   "source": [
    "The remote database instance should now have the data needed to try out the decorator running in the service. We can view some of the data with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03d7cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ssn     | first_name | last_name \n",
      "-------------+------------+-----------\n",
      " 646-87-1351 | Vickie     | Anderson\n",
      " 194-94-3733 | Patricia   | Lee\n",
      " 709-08-5148 | Seth       | James\n",
      " 132-30-5594 | Edward     | Allen\n",
      " 096-55-1187 | Mark       | Keith\n",
      "(5 rows)\n",
      "\n",
      "pod \"postgres-postgresql-client\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl run postgres-postgresql-client --rm --tty -i \\\n",
    "    --restart='Never' \\\n",
    "    --image docker.io/bitnami/postgresql:14.2.0-debian-10-r77 \\\n",
    "    --command -- psql postgresql://postgres:SaF0fhHrRj@postgres-postgresql:5432/postgres \\\n",
    "                -c \"SELECT ssn, first_name, last_name FROM clients LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04749da7",
   "metadata": {},
   "source": [
    "Now that we're done putting data in the database, we can shut down the port forwarding process by pressing CTL-C or with this command:\n",
    "\n",
    "```bash\n",
    "pkill -f kubectl port-forward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17fe95",
   "metadata": {},
   "source": [
    "### Creating a Kubernetes Deployment and Service\n",
    "\n",
    "The model service now has a database to access, so we'll be creating the model service resources. These are:\n",
    "\n",
    "- Deployment: a declarative way to manage a set of pods, the model service pods are managed through the Deployment.\n",
    "- Service: a way to expose a set of pods in a Deployment, the model services is made available to the outside world through the Service, the service type is LoadBalancer which means that a load balancer will be created for the service.\n",
    "\n",
    "They are created within the Kubernetes cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f31011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/insurance-charges-model-deployment created\n",
      "service/insurance-charges-model-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes/model_service.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c203fb",
   "metadata": {},
   "source": [
    "The deployment and service for the model service were created together. You can see the new service with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cd4c93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\r\n",
      "insurance-charges-model-service   LoadBalancer   10.245.246.238   <pending>     80:31223/TCP   32s\r\n",
      "postgres-postgresql               ClusterIP      10.245.0.250     <none>        5432/TCP       15m\r\n",
      "postgres-postgresql-hl            ClusterIP      None             <none>        5432/TCP       15m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487eb4a",
   "metadata": {},
   "source": [
    "The Service type is LoadBalancer, which means that the cloud provider is providing a load balancer and public IP address through which we can contact the service. To view details about the load balancer provided by Digital Ocean for this Service, we'll execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd2af10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoadBalancer Ingress:     157.230.202.103\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe service insurance-charges-model-service | grep \"LoadBalancer Ingress\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829870c4",
   "metadata": {},
   "source": [
    "The load balancer can take a while longer than the service to come up, until the load balancer is running the command won't return anything. The IP address that the Digital Ocean load balancer sits behind will be listed in the output of the command. \n",
    "\n",
    "Once the load balancer comes up, we can view the service through a web browser:\n",
    "\n",
    "![FastAPI Documentation](service_documentation.png)\n",
    "![FastAPI Documentation]({attach}service_documentation.png){ width=100% }\n",
    "\n",
    "The same documentation is displayes as when we deployed the service locally.\n",
    "\n",
    "To make a prediction, we'll hit the IP service with a request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0931126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":6416.86}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://157.230.202.103/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \"ssn\": \"646-87-1351\" }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98447db8",
   "metadata": {},
   "source": [
    "The decorator is working and accessing data from the database!\n",
    "\n",
    "The service is using the configuration file in ./configuration/kubernetes_rest_config.yaml right now, which is configuring the PostgreSQL decorator to accept the \"ssn\" field and use it to load all other features needed by the model from the database. This is not the only way that we can use the decorator, so we'll try out another configuration. \n",
    "\n",
    "To load another configuration file, we'll just change the environment variable value in the Kubernetes Deployment resource for the model service:\n",
    "\n",
    "```yaml\n",
    "env:\n",
    "  - name: REST_CONFIG\n",
    "    value: ./configuration/kubernetes_rest_config2.yaml\n",
    "...\n",
    "```\n",
    "\n",
    "The new configuration file causes the decorator to accept more fields from the user of the service. After changing the Deployment, we'll recreate it in the cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db964f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/insurance-charges-model-deployment configured\n",
      "service/insurance-charges-model-service unchanged\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes/model_service.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a0ea8",
   "metadata": {},
   "source": [
    "The service pods are restarted with the new configuration, the service remains unchanhed. We can try out a request with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d64ba391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":46627.88}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://157.230.202.103/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d \"{ \\\n",
    "      \\\"ssn\\\": \\\"646-87-1351\\\", \\\n",
    "      \\\"age\\\": 65, \\\n",
    "      \\\"bmi\\\": 50, \\\n",
    "      \\\"smoker\\\": true \\\n",
    "    }\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48533603",
   "metadata": {},
   "source": [
    "The service now required more fields because the decorator is no longer loading those features from the database.\n",
    "\n",
    "We'll try out one more configuration to show how powerful decorators can be. In a [previous blog post](https://www.tekhnoal.com/ml-model-decorators.html) we created a decorator that added a unique prediction id to every prediction returned by the model. We can add this decorator to the service by simply changing the configuration:\n",
    "\n",
    "```yaml\n",
    "decorators:\n",
    "  - class_path: data_enrichment.prediction_id.PredictionIDDecorator\n",
    "  - class_path: data_enrichment.postgresql.PostgreSQLEnrichmentDecorator\n",
    "    configuration:\n",
    "    host: \"postgres-postgresql.model-services.svc.cluster.local\"\n",
    "    port: \"5432\"\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a1830",
   "metadata": {},
   "source": [
    "This configuration is in the ./configuration/kubernetes_rest_config3.yaml file. We recreate the Deployment again, this time pointing at this configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b27b8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/insurance-charges-model-deployment configured\n",
      "service/insurance-charges-model-service unchanged\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes/model_service.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02073e8",
   "metadata": {},
   "source": [
    "We'll try the service one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4db224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"charges\":46627.88,\"prediction_id\":\"4db189c2-5200-44a6-b6af-0e341d0fb9bc\"}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://157.230.202.103/api/models/insurance_charges_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d \"{ \\\n",
    "      \\\"ssn\\\": \\\"646-87-1351\\\", \\\n",
    "      \\\"age\\\": 65, \\\n",
    "      \\\"bmi\\\": 50, \\\n",
    "      \\\"smoker\\\": true \\\n",
    "    }\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcf775",
   "metadata": {},
   "source": [
    "The service returned a unique identifier field called \"prediction_id\" along with the prediction. This field was generated by the decorator we added through configuration. A full explanation of how the prediction ID decorator works can be found in the blog post.\n",
    "\n",
    "This shows how easy and powerful it is to combine decorator with models in order to do more complex operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4a67d",
   "metadata": {},
   "source": [
    "### Deleting the Resources\n",
    "\n",
    "Now that we're done with the service we need to destroy the resources. To delete the database deploymet, we'll delete the helm deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd291952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"postgres\" uninstalled\r\n"
     ]
    }
   ],
   "source": [
    "!helm delete postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c75455",
   "metadata": {},
   "source": [
    "Since the persistent volume claim is not deleted with the chart, we'll delete it with a kubectl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0850a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim \"data-postgres-postgresql-0\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete pvc -l app.kubernetes.io/instance=postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20037f7e",
   "metadata": {},
   "source": [
    "To delete the model service, we'll execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b8e2229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"insurance-charges-model-deployment\" deleted\n",
      "service \"insurance-charges-model-service\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f kubernetes/model_service.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9bb190",
   "metadata": {},
   "source": [
    "To delete the namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8ae545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace \"model-services\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f kubernetes/namespace.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e2787",
   "metadata": {},
   "source": [
    "Lastly, to destroy the kubernetes cluster, execute these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "305992b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brian/Code/data-enrichment-for-ml-models/terraform\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Refreshing state... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry.container_registry: Refreshing state... [id=model-services-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry_docker_credentials.registry_credentials: Refreshing state... [id=model-services-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Refreshing state... [id=7eda057c-501f-414c-ad36-e4a75feac4e0]\u001b[0m\n",
      "\u001b[0m\u001b[1mkubernetes_secret.cluster_registry_crendentials: Refreshing state... [id=default/docker-cfg]\u001b[0m\n",
      "\n",
      "Terraform used the selected providers to generate the following execution plan.\n",
      "Resource actions are indicated with the following symbols:\n",
      "  \u001b[31m-\u001b[0m destroy\n",
      "\u001b[0m\n",
      "Terraform will perform the following actions:\n",
      "\n",
      "\u001b[1m  # digitalocean_container_registry.container_registry\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_container_registry\" \"container_registry\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m             = \"2022-05-02 00:48:55 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m               = \"registry.digitalocean.com/model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                     = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m                   = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m                 = \"sfo3\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mserver_url\u001b[0m\u001b[0m             = \"registry.digitalocean.com\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstorage_usage_bytes\u001b[0m\u001b[0m    = 694379520 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msubscription_tier_slug\u001b[0m\u001b[0m = \"basic\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_container_registry_docker_credentials.registry_credentials\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_container_registry_docker_credentials\" \"registry_credentials\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcredential_expiration_time\u001b[0m\u001b[0m = \"2072-04-19T00:48:56Z\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdocker_credentials\u001b[0m\u001b[0m         = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mexpiry_seconds\u001b[0m\u001b[0m             = 1576800000 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                         = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_name\u001b[0m\u001b[0m              = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mwrite\u001b[0m\u001b[0m                      = true \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_kubernetes_cluster.cluster\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_cluster\" \"cluster\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_upgrade\u001b[0m\u001b[0m   = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_subnet\u001b[0m\u001b[0m = \"10.244.0.0/16\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m     = \"2022-05-02 00:48:53 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m       = \"https://7eda057c-501f-414c-ad36-e4a75feac4e0.k8s.ondigitalocean.com\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mha\u001b[0m\u001b[0m             = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m             = \"7eda057c-501f-414c-ad36-e4a75feac4e0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mipv4_address\u001b[0m\u001b[0m   = \"198.211.106.33\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mkube_config\u001b[0m\u001b[0m    = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m           = \"model-services-cluster\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m         = \"nyc1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mservice_subnet\u001b[0m\u001b[0m = \"10.245.0.0/16\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstatus\u001b[0m\u001b[0m         = \"running\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msurge_upgrade\u001b[0m\u001b[0m  = true \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m           = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m     = \"2022-05-02 03:53:30 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m            = \"do:kubernetes:7eda057c-501f-414c-ad36-e4a75feac4e0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mversion\u001b[0m\u001b[0m        = \"1.22.8-do.1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mvpc_uuid\u001b[0m\u001b[0m       = \"5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mmaintenance_policy {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mday\u001b[0m\u001b[0m        = \"sunday\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mduration\u001b[0m\u001b[0m   = \"4h0m0s\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstart_time\u001b[0m\u001b[0m = \"04:00\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mnode_pool {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = 3 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = \"101cdd65-cacc-485e-b773-96176e022e75\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mlabels\u001b[0m\u001b[0m            = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmax_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmin_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"model-services-cluster-worker-pool\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 3 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = [\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-05-02 00:48:53 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"297996322\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"7c974ff8-962a-4450-8eb8-775a562e3c21\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"model-services-cluster-worker-pool-crmkf\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-05-02 00:52:21 +0000 UTC\"\n",
      "                },\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-05-02 00:48:53 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"297996321\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"8275036d-9186-44fa-832a-a68ebe17767e\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"model-services-cluster-worker-pool-crmky\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-05-02 00:52:21 +0000 UTC\"\n",
      "                },\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-05-02 00:48:53 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"297996320\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"54d31e53-dce6-43a2-b090-5d2f86e4902b\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"model-services-cluster-worker-pool-crmkx\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-05-02 00:52:21 +0000 UTC\"\n",
      "                },\n",
      "            ] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-2vcpu-2gb\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m              = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_vpc.cluster_vpc\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_vpc\" \"cluster_vpc\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = \"2022-05-02 00:48:52 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdefault\u001b[0m\u001b[0m    = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = \"5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mip_range\u001b[0m\u001b[0m   = \"10.116.16.0/20\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"model-services-vpc\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m     = \"nyc1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m        = \"do:vpc:5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # kubernetes_secret.cluster_registry_crendentials\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"kubernetes_secret\" \"cluster_registry_crendentials\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdata\u001b[0m\u001b[0m      = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m        = \"default/docker-cfg\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mimmutable\u001b[0m\u001b[0m = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtype\u001b[0m\u001b[0m      = \"kubernetes.io/dockerconfigjson\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mmetadata {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mannotations\u001b[0m\u001b[0m      = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mgeneration\u001b[0m\u001b[0m       = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mlabels\u001b[0m\u001b[0m           = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m             = \"docker-cfg\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnamespace\u001b[0m\u001b[0m        = \"default\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mresource_version\u001b[0m\u001b[0m = \"1218\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0muid\u001b[0m\u001b[0m              = \"2b5bc009-975a-4c32-aa2b-eb667cbf6e6c\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[0m\u001b[1mPlan:\u001b[0m 0 to add, 0 to change, 5 to destroy.\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[1mChanges to Outputs:\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mkubernetes_cluster_id\u001b[0m\u001b[0m = \"7eda057c-501f-414c-ad36-e4a75feac4e0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_endpoint\u001b[0m\u001b[0m     = \"registry.digitalocean.com/model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\u001b[90m\n",
      "───────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\n",
      "Note: You didn't use the -out option to save this plan, so Terraform can't\n",
      "guarantee to take exactly these actions if you run \"terraform apply\" now.\n"
     ]
    }
   ],
   "source": [
    "%cd ./terraform\n",
    "\n",
    "!terraform plan -var=\"project_name=model-services\" -destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03876695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mdigitalocean_container_registry.container_registry: Refreshing state... [id=model-services-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Refreshing state... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry_docker_credentials.registry_credentials: Refreshing state... [id=model-services-registry]\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Refreshing state... [id=7eda057c-501f-414c-ad36-e4a75feac4e0]\u001b[0m\n",
      "\u001b[0m\u001b[1mkubernetes_secret.cluster_registry_crendentials: Refreshing state... [id=default/docker-cfg]\u001b[0m\n",
      "\n",
      "Terraform used the selected providers to generate the following execution plan.\n",
      "Resource actions are indicated with the following symbols:\n",
      "  \u001b[31m-\u001b[0m destroy\n",
      "\u001b[0m\n",
      "Terraform will perform the following actions:\n",
      "\n",
      "\u001b[1m  # digitalocean_container_registry.container_registry\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_container_registry\" \"container_registry\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m             = \"2022-05-02 00:48:55 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m               = \"registry.digitalocean.com/model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                     = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m                   = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m                 = \"sfo3\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mserver_url\u001b[0m\u001b[0m             = \"registry.digitalocean.com\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstorage_usage_bytes\u001b[0m\u001b[0m    = 694379520 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msubscription_tier_slug\u001b[0m\u001b[0m = \"basic\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_container_registry_docker_credentials.registry_credentials\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_container_registry_docker_credentials\" \"registry_credentials\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcredential_expiration_time\u001b[0m\u001b[0m = \"2072-04-19T00:48:56Z\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdocker_credentials\u001b[0m\u001b[0m         = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mexpiry_seconds\u001b[0m\u001b[0m             = 1576800000 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                         = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_name\u001b[0m\u001b[0m              = \"model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mwrite\u001b[0m\u001b[0m                      = true \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_kubernetes_cluster.cluster\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_kubernetes_cluster\" \"cluster\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_upgrade\u001b[0m\u001b[0m   = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcluster_subnet\u001b[0m\u001b[0m = \"10.244.0.0/16\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m     = \"2022-05-02 00:48:53 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mendpoint\u001b[0m\u001b[0m       = \"https://7eda057c-501f-414c-ad36-e4a75feac4e0.k8s.ondigitalocean.com\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mha\u001b[0m\u001b[0m             = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m             = \"7eda057c-501f-414c-ad36-e4a75feac4e0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mipv4_address\u001b[0m\u001b[0m   = \"198.211.106.33\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mkube_config\u001b[0m\u001b[0m    = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m           = \"model-services-cluster\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m         = \"nyc1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mservice_subnet\u001b[0m\u001b[0m = \"10.245.0.0/16\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstatus\u001b[0m\u001b[0m         = \"running\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msurge_upgrade\u001b[0m\u001b[0m  = true \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m           = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mupdated_at\u001b[0m\u001b[0m     = \"2022-05-02 03:53:30 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m            = \"do:kubernetes:7eda057c-501f-414c-ad36-e4a75feac4e0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mversion\u001b[0m\u001b[0m        = \"1.22.8-do.1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mvpc_uuid\u001b[0m\u001b[0m       = \"5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mmaintenance_policy {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mday\u001b[0m\u001b[0m        = \"sunday\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mduration\u001b[0m\u001b[0m   = \"4h0m0s\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mstart_time\u001b[0m\u001b[0m = \"04:00\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mnode_pool {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mactual_node_count\u001b[0m\u001b[0m = 3 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mauto_scale\u001b[0m\u001b[0m        = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m                = \"101cdd65-cacc-485e-b773-96176e022e75\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mlabels\u001b[0m\u001b[0m            = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmax_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mmin_nodes\u001b[0m\u001b[0m         = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m              = \"model-services-cluster-worker-pool\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnode_count\u001b[0m\u001b[0m        = 3 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnodes\u001b[0m\u001b[0m             = [\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-05-02 00:48:53 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"297996322\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"7c974ff8-962a-4450-8eb8-775a562e3c21\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"model-services-cluster-worker-pool-crmkf\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-05-02 00:52:21 +0000 UTC\"\n",
      "                },\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-05-02 00:48:53 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"297996321\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"8275036d-9186-44fa-832a-a68ebe17767e\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"model-services-cluster-worker-pool-crmky\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-05-02 00:52:21 +0000 UTC\"\n",
      "                },\n",
      "              \u001b[31m-\u001b[0m \u001b[0m{\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mcreated_at = \"2022-05-02 00:48:53 +0000 UTC\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mdroplet_id = \"297996320\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mid         = \"54d31e53-dce6-43a2-b090-5d2f86e4902b\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mname       = \"model-services-cluster-worker-pool-crmkx\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mstatus     = \"running\"\n",
      "                  \u001b[31m-\u001b[0m \u001b[0mupdated_at = \"2022-05-02 00:52:21 +0000 UTC\"\n",
      "                },\n",
      "            ] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0msize\u001b[0m\u001b[0m              = \"s-2vcpu-2gb\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtags\u001b[0m\u001b[0m              = [] \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[1m  # digitalocean_vpc.cluster_vpc\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"digitalocean_vpc\" \"cluster_vpc\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mcreated_at\u001b[0m\u001b[0m = \"2022-05-02 00:48:52 +0000 UTC\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdefault\u001b[0m\u001b[0m    = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m         = \"5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mip_range\u001b[0m\u001b[0m   = \"10.116.16.0/20\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m       = \"model-services-vpc\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregion\u001b[0m\u001b[0m     = \"nyc1\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0murn\u001b[0m\u001b[0m        = \"do:vpc:5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1m  # kubernetes_secret.cluster_registry_crendentials\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"kubernetes_secret\" \"cluster_registry_crendentials\" {\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mdata\u001b[0m\u001b[0m      = (sensitive value)\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mid\u001b[0m\u001b[0m        = \"default/docker-cfg\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mimmutable\u001b[0m\u001b[0m = false \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mtype\u001b[0m\u001b[0m      = \"kubernetes.io/dockerconfigjson\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "\n",
      "      \u001b[31m-\u001b[0m \u001b[0mmetadata {\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mannotations\u001b[0m\u001b[0m      = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mgeneration\u001b[0m\u001b[0m       = 0 \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mlabels\u001b[0m\u001b[0m           = {} \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mname\u001b[0m\u001b[0m             = \"docker-cfg\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mnamespace\u001b[0m\u001b[0m        = \"default\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mresource_version\u001b[0m\u001b[0m = \"1218\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0muid\u001b[0m\u001b[0m              = \"2b5bc009-975a-4c32-aa2b-eb667cbf6e6c\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "        }\n",
      "    }\n",
      "\n",
      "\u001b[0m\u001b[1mPlan:\u001b[0m 0 to add, 0 to change, 5 to destroy.\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[1mChanges to Outputs:\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mkubernetes_cluster_id\u001b[0m\u001b[0m = \"7eda057c-501f-414c-ad36-e4a75feac4e0\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m \u001b[0m\u001b[1m\u001b[0mregistry_endpoint\u001b[0m\u001b[0m     = \"registry.digitalocean.com/model-services-registry\" \u001b[90m->\u001b[0m \u001b[0m\u001b[90mnull\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mkubernetes_secret.cluster_registry_crendentials: Destroying... [id=default/docker-cfg]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mkubernetes_secret.cluster_registry_crendentials: Destruction complete after 0s\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry_docker_credentials.registry_credentials: Destroying... [id=model-services-registry]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Destroying... [id=7eda057c-501f-414c-ad36-e4a75feac4e0]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry_docker_credentials.registry_credentials: Destruction complete after 0s\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry.container_registry: Destroying... [id=model-services-registry]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_kubernetes_cluster.cluster: Destruction complete after 1s\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_container_registry.container_registry: Destruction complete after 1s\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 1m0s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 1m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 1m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 1m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 1m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mdigitalocean_vpc.cluster_vpc: Still destroying... [id=5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84, 1m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[31m╷\u001b[0m\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[0m\u001b[1m\u001b[31mError: \u001b[0m\u001b[0m\u001b[1mDELETE https://api.digitalocean.com/v2/vpcs/5a0e94f2-bb9d-4814-bf5f-ccc2c2e98b84: 403 (request \"5ddc337d-916c-43a4-a683-46d51da81510\") Can not delete VPC with members\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[0m\u001b[0m\n",
      "\u001b[31m╵\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!terraform apply -var=\"project_name=model-services\" -auto-approve -destroy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea95e66",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "In this blog post, we showed how to use decorators to perform data enrichment for machine learning models. Data enrichment is a common requirement across many different ML model deployments. We went through the entire design and coding process for the decorator, local testing using Docker, creating the infrastucture using Terraform, and then deploying the solution to Kubernetes.\n",
    "\n",
    "One of the benefits of using a decorator for the ML model is that we keep the model prediction code and the data access code separate from each other. The model code did not have to change at all for us to be able to perform data enrichment for the model. The RESTful service package code also didnt have to be modified because it supports adding decorators to models through configuration rather than doing it through code. In the end it was possible to cleanly combine the model, decorator, and service components into one cohesive solution through the use of configuration only. The service is also able to host multiple decorators for each model which also allows for more complex use cases for decorators.\n",
    "\n",
    "Another benefit is that we are able to reuse the decorator we built in this blog post to do data enrichment for any ML model deployment that needs to pull data from a PostgreSQL database. The same decorator class can easily be instantiated and added to any model instance that follows the MLModel interface. We can do this because the decorator is built for flexibility, being able to be configured to load any number of fields from a database table and join the values into the model's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07af0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
